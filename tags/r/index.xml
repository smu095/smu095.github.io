<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Biased</title>
    <link>/tags/r/</link>
    <description>Recent content in R on Biased</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Sean Meling Murray</copyright>
    <lastBuildDate>Fri, 12 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>#theriddler: Simulating spelling bees (updated 15.04.19)</title>
      <link>/2019/04/12/2019-04-12-theriddler-simulating-spelling-bees/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/12/2019-04-12-theriddler-simulating-spelling-bees/</guid>
      <description>This week RStudio v1.2 was released. The newest version of the popular IDE has support for the supercool reticulate package which allows us to run Python chunks in R notebooks.
Getting started is as simple as loading reticulate and replacing the chunk ```{r} # Your R code here ``` with ```{python} # Your Python code here ```. Furthermore, reticulate has support for loading Python environments. In the example below, I access a conda environment named ml that contains all my machine learning modules.</description>
    </item>
    
    <item>
      <title>#tidytuesday: Women in the workforce</title>
      <link>/2019/03/13/2019-03-13-tidytuesday-women-in-the-workforce/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/13/2019-03-13-tidytuesday-women-in-the-workforce/</guid>
      <description>Last week’s #tidytuesday data about women in the workforce is provided by the Bureau of Labor Statistics and the Census Bureau.
As usual, we start by skimming the data to get a quick overview:
# Setup library(tidyverse) library(skimr) # Loading data csv &amp;lt;- &amp;quot;~/Documents/Github/tidytuesday/data/2019/2019-03-05/jobs_gender.csv&amp;quot; jobs_gender &amp;lt;- read_csv(csv) jobs_gender %&amp;gt;% skim  There are some missing values in total_earnings_female (estimated median wages for females). There are also quite a few NA’s in wage_percent_of_male (female wages as percent of male wages), which according to the #tidytuesday repo indicates small sample sizes for those occupations.</description>
    </item>
    
    <item>
      <title>#tidytuesday: Special binary operators and plotting PhDs</title>
      <link>/2019/02/20/2019-02-20-tidytuesday-special-binary-operators-and-plotting-phds/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/20/2019-02-20-tidytuesday-special-binary-operators-and-plotting-phds/</guid>
      <description>If you’re familiar with the tidyverse, you’re most likely familiar with the pipe operator %&amp;gt;% from magrittr. The pipe operators
 pipe their left-hand side values forward into expressions that appear on the right-hand side, i.e. one can replace f(x) with x %&amp;gt;% f(), where %&amp;gt;% is the (main) pipe-operator (https://magrittr.tidyverse.org/).
 %&amp;gt;% is an example of a special binary operator. Now, what’s cool about special binary operators is that we can define our own!</description>
    </item>
    
    <item>
      <title>#tidytuesday: Fitting multiple time-series models using purrr</title>
      <link>/2019/02/16/2019-02-16-tidytuesday-fitting-multiple-time-series-models-using-purrr/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/16/2019-02-16-tidytuesday-fitting-multiple-time-series-models-using-purrr/</guid>
      <description>This week I want to try to use purrr to model many data sets efficiently. There are many great resources available; in this post we primarily rely on the following sources:
 Managing Many Models with tidyr, purrr and broom. Purrr - tips and tricks. Many models (chapter 25 in R for Data Science).  Most of my modelling experience comes from using scikit-learn in Python. In R, the parsnip package from tidymodels seems like an extremely promising approach that I will try to explore in future posts.</description>
    </item>
    
    <item>
      <title>#tidytuesday: Skimr, regular expressions and recessions</title>
      <link>/2019/02/08/2019-02-08-tidytuesday-skimr-regular-expressions-and-recessions/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/08/2019-02-08-tidytuesday-skimr-regular-expressions-and-recessions/</guid>
      <description>This week’s post will mark the start of my experimentation with purrr and regular expressions (regex). I’ll also take a look at a package called skimr, which looks like a pretty efficient way to get a quick overview of our data.
In case you don’t know, purrr essentially abstracts away the need for many kinds of for loops used to iterate over lists or atomic vectors. As Hadley writes in R for Data Science, the apply family of functions solve a similar problem, but purrr provides a more consistent and easier-to-learn approach.</description>
    </item>
    
    <item>
      <title>#tidytuesday: Making BBC style plots with bbplot</title>
      <link>/2019/02/03/2019-02-03-tidytuesday-making-bbc-style-plots-with-bbplot/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/03/2019-02-03-tidytuesday-making-bbc-style-plots-with-bbplot/</guid>
      <description>I must admit that I wasn’t too excited about this week’s #tidytuesday dataset from the United States Department of Agriculture (USDA) concerning cows and milk products. I thought I might give it a rest this week, but then I stumbled across a post on r/rstats linking to this Medium post by the folks at the BBC’s department for visual and data journalism.
In brief, the post describes how the team transitioned from exploring data using ggplot2, to using the tidyverse to produce publication-ready plots.</description>
    </item>
    
    <item>
      <title>#tidytuesday: Exploring (missing) data with maps</title>
      <link>/2019/01/27/2019-01-26-tidy-tuesday-2-plotting-geospatial-data-with-ggplot2/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/27/2019-01-26-tidy-tuesday-2-plotting-geospatial-data-with-ggplot2/</guid>
      <description>This week’s #tidytuesday data is the incarceration trends data set from the Vera Institute of Justice, which contains county-level jail data (1970-2015) and prison data (1983-2015). Vera is a non-profit research and policy organisation focusing on “the causes and consequences of mass incarceration, racial disparities, and the loss of public trust in law enforcement” (see the Wikipedia article for more).
I’ve been thinking about exploring maps in R but never gotten around to it, so this seemed like a great opportunity.</description>
    </item>
    
    <item>
      <title>First foray into Tidy Tuesday</title>
      <link>/2019/01/22/2019-01-22-first-foray-into-tidytuesday/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/22/2019-01-22-first-foray-into-tidytuesday/</guid>
      <description>This week was my Tidy Tuesday debut! Tidy Tuesday is a weekly data project which is aimed at R users who want to practice their wrangling and visualisation skills within the tidyverse. This week’s data set features a historical record of rocket launches, and formed the basis for the article “The space race is dominated by new contenders”.
My goals for this week were to:
 Expose myself to gganimate, a really nifty package that extends ggplot2 to include animations.</description>
    </item>
    
  </channel>
</rss>